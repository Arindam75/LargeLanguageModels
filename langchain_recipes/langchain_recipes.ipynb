{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "import os\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "HF_API_KEY = os.getenv(\"HF_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic usage by using the Huggingface API. Langchain 0.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arind\\Documents\\LargeLanguageModels\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEndpoint` was deprecated in LangChain 0.0.37 and will be removed in 0.3. An updated version of the class exists in the from langchain-huggingface package and should be used instead. To use it run `pip install -U from langchain-huggingface` and import as `from from langchain_huggingface import llms import HuggingFaceEndpoint`.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\arind\\Documents\\LargeLanguageModels\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\arind\\.cache\\huggingface\\token\n",
      "Login successful\n",
      "\n",
      "The second annual National Shoe Month is a chance to look after your feet\n",
      "The National Shoe Month campaign will run from 3rd-8th October\n",
      "Don’t forget to get your feet checked by a foot specialist\n",
      "Health\n",
      "Do you need to change the way you think about feet? Then come and meet the Foot Health Services at the National Shoe Month Health Check\n",
      "Fashions on the Foot – an exciting new fashion show on 22nd October, 1-3pm\n",
      "Social media\n",
      "We have lots of activities on offer, so make sure you share your photos with us and tag us in.\n",
      "Download the National Shoe Month logo and use it on your social media pages to show support for National Shoe Month.\n",
      "Facebook and Twitter\n",
      "Hashtag: #NShoeMonth\n",
      "In addition, a range of creative media images have been created to promote National Shoe Month.\n",
      "Download the images here:\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms.huggingface_endpoint import HuggingFaceEndpoint\n",
    "\n",
    "# Set your Hugging Face API token \n",
    "huggingfacehub_api_token = HF_API_KEY\n",
    "\n",
    "# Define the LLM\n",
    "llm = HuggingFaceEndpoint(repo_id='tiiuae/falcon-7b-instruct', huggingfacehub_api_token=huggingfacehub_api_token)\n",
    "\n",
    "# Predict the words following the text in question\n",
    "question = 'Whatever you do, take care of your shoes'\n",
    "output = llm.invoke(question)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using OPenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". If you don't, it's quite likely they won't last for very long. This is especially important for high-quality shoes, as they can be quite an investment. Here are some tips for taking care of your shoes and making sure they stay in good condition for as long as possible.\n",
      "\n",
      "1. Clean and polish regularly\n",
      "\n",
      "One of the most important things you can do to take care of your shoes is to clean and polish them regularly. This not only keeps them looking clean and shiny, but it also helps to protect the leather and keep it from drying out and cracking. Use a soft cloth to wipe away any dirt or debris, and then apply a leather conditioner or polish to keep the leather supple.\n",
      "\n",
      "2. Rotate your shoes\n",
      "\n",
      "Wearing the same pair of shoes every day can cause them to wear out more quickly. To extend the life of your shoes, try to rotate them and give them a break between wears. This also allows them to dry out and air out, which can help prevent odors and bacteria growth.\n",
      "\n",
      "3. Use shoe trees\n",
      "\n",
      "Investing in a good pair of shoe trees can help your shoes maintain their shape and prevent creasing. They also absorb moisture and odors, helping to keep your shoes fresh. Insert them into your shoes whenever\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "# Set your API Key from OpenAI\n",
    "openai_api_key = OPENAI_API_KEY\n",
    "\n",
    "# Define the LLM\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", openai_api_key=openai_api_key)\n",
    "\n",
    "# Predict the words following the text in question\n",
    "question = 'Whatever you do, take care of your shoes'\n",
    "output = llm.invoke(question)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\arind\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arind\\Documents\\LargeLanguageModels\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\arind\\Documents\\LargeLanguageModels\\venv\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LangChain simplifies LLM application development by providing a single platform for managing all languages, reducing the need for manual handling of language-specific libraries and APIs, and making it easier to switch between languages during development.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# Create a prompt template from the template string\n",
    "template = \"You are an artificial intelligence assistant, answer the question. {question}\"\n",
    "prompt = PromptTemplate(template = template, input_variables = [\"question\"])\n",
    "\n",
    "# Create a chain to integrate the prompt template and LLM\n",
    "llm = HuggingFaceEndpoint(repo_id='tiiuae/falcon-7b-instruct', huggingfacehub_api_token = HF_API_KEY)\n",
    "llm_chain = LLMChain(prompt = prompt, llm = llm)\n",
    "\n",
    "question = \"How does LangChain make LLM application development easier?\"\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
