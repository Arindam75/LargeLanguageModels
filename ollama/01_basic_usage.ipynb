{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming Ollama is installed and the llm being used is already pulled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why did the moon go to the party? Because it was a \"lunar\" invitation!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = Ollama(\n",
    "    model=\"llama2\"\n",
    ")\n",
    "llm.invoke(\"Tell me a joke about the moon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using With Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The sun rises slow and bright,\n",
      "A new day dawns with gentle light.\n",
      "The world awakens from its sleep,\n",
      "As nature's beauty begins to peep.\n",
      "\n",
      "The sky is painted red and gold,\n",
      "As morning breaks the darkness cold.\n",
      "The sun climbs high in the sky's embrace,\n",
      "Bringing warmth and light to the place.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOllama(model=\"llama2\")\n",
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a poem on the topic: {topic}. Limit the output to 12 lines.\" \n",
    ")\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "print(chain.invoke({\"topic\": \"sunrise\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "\n",
    "The embedding model nomic-embed-text is already pulled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:03<00:00,  3.78s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.008237600326538,\n",
       " 0.7910909652709961,\n",
       " -4.304612636566162,\n",
       " -1.1145471334457397,\n",
       " 1.0041004419326782,\n",
       " -0.49756401777267456,\n",
       " 0.26684460043907166,\n",
       " 0.2242097705602646,\n",
       " 0.43466249108314514,\n",
       " -0.7883084416389465]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "embeddings = (\n",
    "    OllamaEmbeddings(model = \"nomic-embed-text\",  show_progress = True)\n",
    ") \n",
    "\n",
    "text = \"This is a test document.\"\n",
    "\n",
    "query_result = embeddings.embed_query(text)\n",
    "query_result[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
