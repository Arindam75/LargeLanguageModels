{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP65gwJFlfqbeKZ+Ff9XNNl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arindam75/LargeLanguageModels/blob/main/LLM_FineTuning_QA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Packages"
      ],
      "metadata": {
        "id": "p866Z-J6VhBG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ0XAk6CVMiX",
        "outputId": "5469c6ff-5978-4b8f-9029-dfd8640bcdef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Collecting pyarrow>=12.0.0 (from datasets)\n",
            "  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Collecting responses<0.19 (from evaluate)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow, dill, responses, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 10.0.1\n",
            "    Uninstalling pyarrow-10.0.1:\n",
            "      Successfully uninstalled pyarrow-10.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 15.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.17.0 dill-0.3.8 evaluate-0.4.1 multiprocess-0.70.16 pyarrow-15.0.0 responses-0.18.0\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers tokenizers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os,sys\n",
        "import json\n",
        "\n",
        "root_path = \"/content/drive/MyDrive/LLM\"\n",
        "f = open(os.path.join(root_path,\"keyfile.json\"))\n",
        "key_data = json.load(f)\n",
        "hf_key = key_data['my_keys'][1]['hf']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKrAYW29VTFE",
        "outputId": "847eb3da-e6b0-4d0b-c087-1d54c50eee9b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import display, HTML"
      ],
      "metadata": {
        "id": "hDRTZB-kWTaE"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "fCWv2LT-WOre"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load the squad dataset, which is of type __datasets.dataset_dict.DatasetDict__. Once downloaded , we can see that it has 5 key value pairs.\n",
        "\n",
        "- id\n",
        "- title\n",
        "- context\n",
        "- question\n",
        "- answers"
      ],
      "metadata": {
        "id": "zKNs_6UrWh4k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = load_dataset(\"squad\")\n",
        "datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUa36Bz1V05H",
        "outputId": "6dfef7f2-39af-44d3-9324-17e3cbe8d0de"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 87599\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "        num_rows: 10570\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "See 10 random elements from the dataset"
      ],
      "metadata": {
        "id": "Ch4okwZzSxBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_elements = np.random.randint(0, high = len(datasets[\"train\"]), size=10, dtype=int)\n",
        "\n",
        "df = pd.DataFrame(datasets[\"train\"][random_elements])\n",
        "display(HTML(df.to_html()))"
      ],
      "metadata": {
        "id": "hbmfGHpNRlWV"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tJfdWVCfRJ6h",
        "outputId": "cae225c6-4a72-46b5-851d-d716af4dab6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>answers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>56f86baca6d7ea1400e17600</td>\n",
              "      <td>Southampton</td>\n",
              "      <td>630 people lost their lives as a result of the air raids on Southampton and nearly 2,000 more were injured, not to mention the thousands of buildings damaged or destroyed.</td>\n",
              "      <td>In addition to casualties, about how many people were wounded by air raids on Southampton?</td>\n",
              "      <td>{'text': ['2,000'], 'answer_start': [83]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>572b3f4734ae481900dead46</td>\n",
              "      <td>Empiricism</td>\n",
              "      <td>Mill's empiricism thus held that knowledge of any kind is not from direct experience but an inductive inference from direct experience. The problems other philosophers have had with Mill's position center around the following issues: Firstly, Mill's formulation encounters difficulty when it describes what direct experience is by differentiating only between actual and possible sensations. This misses some key discussion concerning conditions under which such \"groups of permanent possibilities of sensation\" might exist in the first place. Berkeley put God in that gap; the phenomenalists, including Mill, essentially left the question unanswered. In the end, lacking an acknowledgement of an aspect of \"reality\" that goes beyond mere \"possibilities of sensation\", such a position leads to a version of subjective idealism. Questions of how floor beams continue to support a floor while unobserved, how trees continue to grow while unobserved and untouched by human hands, etc., remain unanswered, and perhaps unanswerable in these terms. Secondly, Mill's formulation leaves open the unsettling possibility that the \"gap-filling entities are purely possibilities and not actualities at all\". Thirdly, Mill's position, by calling mathematics merely another species of inductive inference, misapprehends mathematics. It fails to fully consider the structure and method of mathematical science, the products of which are arrived at through an internally consistent deductive set of procedures which do not, either today or at the time Mill wrote, fall under the agreed meaning of induction.</td>\n",
              "      <td>What sensations did Mill differentiate?</td>\n",
              "      <td>{'text': ['actual and possible sensations'], 'answer_start': [360]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5730483ea23a5019007fd068</td>\n",
              "      <td>Charleston,_South_Carolina</td>\n",
              "      <td>The City of Charleston Police Department, with a total of 452 sworn officers, 137 civilians, and 27 reserve police officers, is South Carolina's largest police department. Their procedures on cracking down on drug use and gang violence in the city are used as models to other cities to do the same.[citation needed] According to the final 2005 FBI Crime Reports, Charleston crime level is worse than the national average in almost every major category. Greg Mullen, the former Deputy Chief of the Virginia Beach, Virginia Police Department, serves as the current Chief of the Charleston Police Department. The former Charleston police chief was Reuben Greenberg, who resigned August 12, 2005. Greenberg was credited with creating a polite police force that kept police brutality well in check, even as it developed a visible presence in community policing and a significant reduction in crime rates.</td>\n",
              "      <td>How many reserve police officers do the Charleston Police Department have?</td>\n",
              "      <td>{'text': ['27'], 'answer_start': [97]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>572847273acd2414000df85f</td>\n",
              "      <td>John_von_Neumann</td>\n",
              "      <td>Von Neumann was a founding figure in computing. Donald Knuth cites von Neumann as the inventor, in 1945, of the merge sort algorithm, in which the first and second halves of an array are each sorted recursively and then merged. Von Neumann wrote the sorting program for the EDVAC in ink, being 23 pages long; traces can still be seen on the first page of the phrase \"TOP SECRET\", which was written in pencil and later erased. He also worked on the philosophy of artificial intelligence with Alan Turing when the latter visited Princeton in the 1930s.</td>\n",
              "      <td>What does a merge sort algorithm do?</td>\n",
              "      <td>{'text': ['the first and second halves of an array are each sorted recursively and then merged'], 'answer_start': [143]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>572a6eae7a1753140016af45</td>\n",
              "      <td>Friedrich_Hayek</td>\n",
              "      <td>Hayek continued his research on monetary and capital theory, revising his theories of the relations between credit cycles and capital structure in Profits, Interest and Investment (1939) and The Pure Theory of Capital (1941), but his reputation as an economic theorist had by then fallen so much that those works were largely ignored, except for scathing critiques by Nicholas Kaldor. Lionel Robbins himself, who had embraced the Austrian theory of the business cycle in The Great Depression (1934), later regretted having written the book and accepted many of the Keynesian counter-arguments.</td>\n",
              "      <td>What is the name of the first book Hayek released to revise his stances from Prices and Production?</td>\n",
              "      <td>{'text': ['Profits, Interest and Investment'], 'answer_start': [147]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5728240c2ca10214002d9ece</td>\n",
              "      <td>European_Central_Bank</td>\n",
              "      <td>Rescue operations involving sovereign debt have included temporarily moving bad or weak assets off the balance sheets of the weak member banks into the balance sheets of the European Central Bank. Such action is viewed as monetisation and can be seen as an inflationary threat, whereby the strong member countries of the ECB shoulder the burden of monetary expansion (and potential inflation) to save the weak member countries. Most central banks prefer to move weak assets off their balance sheets with some kind of agreement as to how the debt will continue to be serviced. This preference has typically led the ECB to argue that the weaker member countries must:</td>\n",
              "      <td>What is shuffling around bad or weak debts from a weaker eurozone member to the ECB known as?</td>\n",
              "      <td>{'text': ['monetisation'], 'answer_start': [222]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>56fdfa85761e401900d28c88</td>\n",
              "      <td>Computer</td>\n",
              "      <td>I/O is the means by which a computer exchanges information with the outside world. Devices that provide input or output to the computer are called peripherals. On a typical personal computer, peripherals include input devices like the keyboard and mouse, and output devices such as the display and printer. Hard disk drives, floppy disk drives and optical disc drives serve as both input and output devices. Computer networking is another form of I/O.</td>\n",
              "      <td>Hard disk drives are what type of peripheral device?</td>\n",
              "      <td>{'text': ['input and output'], 'answer_start': [382]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>572806d8ff5b5019007d9b34</td>\n",
              "      <td>Gamal_Abdel_Nasser</td>\n",
              "      <td>On 26 July 1956, Nasser gave a speech in Alexandria announcing the nationalization of the Suez Canal Company as a means to fund the Aswan Dam project in light of the British–American withdrawal. In the speech, he denounced British imperialism in Egypt and British control over the canal company's profits, and upheld that the Egyptian people had a right to sovereignty over the waterway, especially since \"120,000 Egyptians had died (sic)\" building it. The motion was technically in breach of the international agreement he had signed with the UK on 19 October 1954, although he ensured that all existing stockholders would be paid off.</td>\n",
              "      <td>What did Nasser propose to do with funds from the nationalized Suez Canal?</td>\n",
              "      <td>{'text': ['fund the Aswan Dam'], 'answer_start': [123]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5734257c4776f41900661964</td>\n",
              "      <td>Infection</td>\n",
              "      <td>The isolation of enzymes from infected tissue can also provide the basis of a biochemical diagnosis of an infectious disease. For example, humans can make neither RNA replicases nor reverse transcriptase, and the presence of these enzymes are characteristic of specific types of viral infections. The ability of the viral protein hemagglutinin to bind red blood cells together into a detectable matrix may also be characterized as a biochemical test for viral infection, although strictly speaking hemagglutinin is not an enzyme and has no metabolic function.</td>\n",
              "      <td>Why are the presence of certain enymzes a tell tale sign of a virus?</td>\n",
              "      <td>{'text': ['humans can make neither RNA replicases nor reverse transcriptase'], 'answer_start': [139]}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>56d9e79adc89441400fdb8f8</td>\n",
              "      <td>Dog</td>\n",
              "      <td>Citing a 2008 study, the U.S. Center for Disease Control estimated in 2015 that 4.5 million people in the USA are bitten by dogs each year. A 2015 study estimated that 1.8% of the U.S. population is bitten each year. In the 1980s and 1990s the US averaged 17 fatalities per year, while in the 2000s this has increased to 26. 77% of dog bites are from the pet of family or friends, and 50% of attacks occur on the property of the dog's legal owner.</td>\n",
              "      <td>According to a 2008 CDC report, how many are bitten in the United States annually?</td>\n",
              "      <td>{'text': ['4.5 million'], 'answer_start': [80]}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are several important fields here:\n",
        "\n",
        "answers: the starting location of the answer token and the answer text.<br>\n",
        "context: background information from which the model needs to extract the answer.<br>\n",
        "question: the question a model should answer."
      ],
      "metadata": {
        "id": "RldfgXwiYYY8"
      }
    }
  ]
}